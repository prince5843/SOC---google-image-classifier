{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f9f6360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae393289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_network(input_shape):\n",
    "    input = tf.keras.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(input)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    return models.Model(input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fa0da06",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (105, 105, 1)\n",
    "base_network = create_base_network(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93fff370",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = tf.keras.Input(shape=input_shape)\n",
    "input_b = tf.keras.Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac9de119",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f78b445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Astha Agarwal\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:192: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distance = layers.Lambda(lambda embeddings: tf.keras.backend.abs(embeddings[0] - embeddings[1]))([processed_a, processed_b])\n",
    "outputs = layers.Dense(1, activation='sigmoid')(distance)\n",
    "model = models.Model([input_a, input_b], outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe7f021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dec96640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filepath):\n",
    "    img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (105, 105))\n",
    "    img = img.astype('float32') / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3942998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare your pairs of images and labels for training\n",
    "def create_pairs(base_image_path, other_image_paths, same_class_paths):\n",
    "    base_image = load_image(base_image_path)\n",
    "    pairs = []\n",
    "    labels = []\n",
    "\n",
    "    for other_image_path in other_image_paths:\n",
    "        other_image = load_image(other_image_path)\n",
    "        pairs.append([base_image, other_image])\n",
    "        labels.append(0)  # Different class\n",
    "\n",
    "    for same_class_path in same_class_paths:\n",
    "        same_class_image = load_image(same_class_path)\n",
    "        pairs.append([base_image, same_class_image])\n",
    "        labels.append(1)  # Same class\n",
    "\n",
    "    return np.array(pairs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90ca1e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_image_path = r\"C:\\Users\\Astha Agarwal\\OneDrive\\Desktop\\learnerSpace_ML\\week4\\srk1.png\"\n",
    "other_image_paths = [r\"C:\\Users\\Astha Agarwal\\OneDrive\\Desktop\\learnerSpace_ML\\week4\\modi1.png\", r\"C:\\Users\\Astha Agarwal\\OneDrive\\Desktop\\learnerSpace_ML\\week4\\modi2.png\"]\n",
    "same_class_paths = [r\"C:\\Users\\Astha Agarwal\\OneDrive\\Desktop\\learnerSpace_ML\\week4\\srk2.png\", r\"C:\\Users\\Astha Agarwal\\OneDrive\\Desktop\\learnerSpace_ML\\week4\\srk2.png\"]\n",
    "\n",
    "pairs, labels = create_pairs(base_image_path, other_image_paths, same_class_paths)\n",
    "pairs = [pairs[:, 0], pairs[:, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e297cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs, labels = create_pairs(base_image_path, other_image_paths, same_class_paths)\n",
    "pairs = [pairs[:, 0], pairs[:, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc105b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.2500 - loss: 0.6916\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.7500 - loss: 0.6320\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 1.0000 - loss: 0.4371\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 1.0000 - loss: 0.2541\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 0.1852\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 1.0000 - loss: 0.1738\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 1.0000 - loss: 0.1727\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 1.0000 - loss: 0.1725\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 1.0000 - loss: 0.1724\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 1.0000 - loss: 0.1723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x29dbf703d50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(pairs, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d415af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
      "Prediction: [[1.3696201e-11]]\n"
     ]
    }
   ],
   "source": [
    "img1 = load_image(r\"C:\\Users\\Astha Agarwal\\OneDrive\\Desktop\\learnerSpace_ML\\week4\\srk1.png\")\n",
    "img2 = load_image(r\"C:\\Users\\Astha Agarwal\\OneDrive\\Desktop\\learnerSpace_ML\\week4\\modi2.png\")\n",
    "prediction = model.predict([np.expand_dims(img1, axis=0), np.expand_dims(img2, axis=0)])\n",
    "print(f'Prediction: {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc882205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 1.0000 - loss: 0.1721\n",
      "Validation Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "val_other_image_paths = [r\"C:\\Users\\Astha Agarwal\\OneDrive\\Desktop\\learnerSpace_ML\\week4\\modi1.png\", r\"C:\\Users\\Astha Agarwal\\OneDrive\\Desktop\\learnerSpace_ML\\week4\\modi2.png\"]\n",
    "val_same_class_paths = [r\"C:\\Users\\Astha Agarwal\\OneDrive\\Desktop\\learnerSpace_ML\\week4\\srk1.png\", r\"C:\\Users\\Astha Agarwal\\OneDrive\\Desktop\\learnerSpace_ML\\week4\\srk2.png\"]\n",
    "\n",
    "val_pairs, val_labels = create_pairs(base_image_path, val_other_image_paths, val_same_class_paths)\n",
    "val_pairs = [val_pairs[:, 0], val_pairs[:, 1]]\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_pairs, val_labels)\n",
    "\n",
    "print(f'Validation Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc0ec34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
